# Text_Clustering_Project

## Описание проекта

Данный проект предназначен для обработки текстовых документов, генерации их эмбеддингов, выполнения кластеризации и классификации новых документов по ближайшему кластеру. Основная цель проекта — автоматизировать процесс анализа и группировки текстовых данных, что может быть полезно для задач обработки естественного языка, анализа данных и работы с большими объемами текстов.

## Структура проекта

- **main.py** — Основной файл проекта, который выполняет следующие задачи:
  1. Чтение и предобработка текстов.
  2. Генерация эмбеддингов для текстов.
  3. Определение оптимального числа кластеров (метод локтя и силуэтный коэффициент).
  4. Кластеризация текстов на основе эмбеддингов.
  5. Классификация нового документа по ближайшему кластеру.

- **src/preprocess.py** — Модуль для чтения и предобработки текстов:
  - `read_text_files(directory)` — Функция для чтения текстовых файлов из директории.
  - `preprocess_text(text)` — Функция для предобработки текста (удаление пунктуации, лемматизация, удаление стоп-слов).
  - `process_all_texts(directory)` — Чтение и предобработка всех текстов из указанной директории.

- **src/embeddings.py** — Модуль для генерации эмбеддингов:
  - `generate_embeddings(texts)` — Преобразование предобработанных текстов в эмбеддинги.
  - `save_embeddings(embeddings, filepath)` — Сохранение эмбеддингов в файл.
  - `load_embeddings(filepath)` — Загрузка эмбеддингов из файла.

- **src/clustering.py** — Модуль для кластеризации:
  - `determine_optimal_clusters(embeddings, max_clusters)` — Определение оптимального числа кластеров методом локтя и силуэтного коэффициента.
  - `cluster_embeddings(embeddings, n_clusters)` — Кластеризация эмбеддингов с использованием алгоритма KMeans.
  - `save_model(model, filepath)` — Сохранение обученной модели кластеризации.
  - `load_model(filepath)` — Загрузка модели кластеризации.

- **src/classify.py** — Модуль для классификации новых документов:
  - `classify_document(new_embedding, cluster_centers)` — Классификация нового документа на основе косинусного расстояния до центров кластеров.
  - `find_nearest_neighbors(embeddings, n_neighbors)` — Создание модели ближайших соседей для поиска ближайших документов.
  - `classify_with_neighbors(new_embedding, model, embeddings)` — Классификация нового документа с использованием ближайших соседей.

## Установка и использование

1. **Клонирование репозитория**
    ```bash
    git clone https://github.com/your-username/text_clustering_project.git
    cd text_clustering_project
    ```

2. **Создание и активация виртуального окружения**
    ```bash
    python -m venv venv
    source venv/bin/activate  # Для Windows: venv\Scripts\activate
    ```

3. **Установка зависимостей**
    ```bash
    pip install -r requirements.txt
    ```

4. **Загрузка модели языка Spacy**
    Для работы с английским языком:
    ```bash
    python -m spacy download en_core_web_lg
    ```
    Для русского языка:
    ```bash
    python -m spacy download ru_core_news_lg
    ```

5. **Запуск проекта**
    ```bash
    python main.py
    ```

## Взаимодействие с программой

После запуска программы будут выполнены следующие шаги:

1. **Чтение и предобработка текстов** — Программа прочитает все `.txt` файлы в директории `data/` и выполнит предобработку текста (удаление стоп-слов, лемматизация).
2. **Генерация эмбеддингов** — Для каждого предобработанного текста будут созданы эмбеддинги с использованием модели `sentence-transformers`.
3. **Определение оптимального числа кластеров** — Построение графиков для метода локтя и силуэтного коэффициента. После этого пользователю предлагается ввести оптимальное количество кластеров.
4. **Кластеризация** — Программа выполнит кластеризацию текстов с использованием алгоритма KMeans и сохранит модель.
5. **Классификация нового документа** — Пользователь может ввести новый текст для классификации, и программа отнесет его к ближайшему кластеру.

## Данные

Для работы проекта требуется наличие текстовых файлов в директории `data/`. Эти файлы будут использоваться для анализа, обработки и кластеризации.

## Требования

Проект требует Python 3.10 и выше. Зависимости перечислены в `requirements.txt`. Дополнительно требуется установка модели Spacy для выбранного языка (английского или русского).
