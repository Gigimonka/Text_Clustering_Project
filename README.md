# Text_Clustering_Project

## Описание проекта

Данный проект предоставляет решения для обработки текстовых документов, создания эмбеддингов, кластеризации и классификации новых текстов на основе ближайшего кластера. Основная цель проекта — автоматизация анализа и группировки текстовых данных для задач обработки естественного языка (NLP), аналитики данных и работы с большими массивами текстов.

## Структура проекта

- **main.py** — Основной файл проекта, который выполняет следующие задачи:
  1. Чтение и предобработка текстов.
  2. Генерация эмбеддингов для текстов.
  3. Определение оптимального числа кластеров (метод локтя и силуэтный коэффициент).
  4. Кластеризация текстов на основе эмбеддингов.
  5. Классификация новых документов по ближайшему кластеру.

- **src/** — Папка, содержащая модули для работы с данными:
  - `preprocess.py` — Модуль для чтения и предобработки текстов:
    - `read_text_files(directory)` — Функция для чтения текстовых файлов из директории.
    - `preprocess_text_spacy(text)` — Функция для предобработки текста (удаление пунктуации, лемматизация, удаление стоп-слов).
    - `process_all_texts(directory)` — Чтение и предобработка всех текстов из указанной директории.
  
  - `embeddings.py` — Модуль для генерации эмбеддингов:
    - `generate_embeddings(texts)` — Преобразование предобработанных текстов в эмбеддинги.
    - `save_embeddings(embeddings, filepath)` — Сохранение эмбеддингов в файл.
    - `load_embeddings(filepath)` — Загрузка эмбеддингов из файла.
    
  - `clustering.py` — Модуль для кластеризации:
    - `find_optimal_clusters(embeddings, max_k)` — Определение оптимального числа кластеров методом локтя и силуэтного анализа.
    - `cluster_embeddings(embeddings, n_clusters)` — Кластеризация эмбеддингов с использованием алгоритма KMeans.
    - `save_model(model, filepath)` — Сохранение обученной модели кластеризации.
    - `load_model(filepath)` — Загрузка модели кластеризации.

  - `classify.py` — Модуль для классификации новых документов:
    - `classify_document(new_embedding, cluster_centers)` — Классификация нового документа на основе косинусного расстояния до центров кластеров.
    - `find_nearest_neighbors(embeddings, n_neighbors)` — Поиск ближайших документов с использованием метода ближайших соседей.
  
  - `visualization.py` — Модуль для визуализации данных:
    - `visualize_clusters` — Визуализация кластеров с использованием метода t-SNE.
    - `visualize_elbow_and_silhouette` — Визуализация метода локтя и силуэтного анализа для выбора оптимального числа кластеров.

- **data/** — Директория, содержащая исходные текстовые данные для кластеризации.

- **new_data/** — Директория, содержащая новые документы для классификации.

- **embeddings/** — Директория для хранения файлов с эмбеддинговыми представлениями текстов (например, `embeddings.pkl`).

- **models/** — Директория для хранения сохраненных моделей (например, KMeans модель сохранена в `kmeans_model.pkl`).

- **requirements.txt** — Список зависимостей проекта.

## Установка и использование

1. **Клонирование репозитория**:
    ```bash
    git clone https://github.com/your-username/text_clustering_project.git
    cd text_clustering_project
    ```

2. **Создание и активация виртуального окружения**:
    ```bash
    python -m venv venv
    source venv/bin/activate  # Для Windows: venv\Scripts\activate
    ```

3. **Установка зависимостей**:
    ```bash
    pip install -r requirements.txt
    ```

4. **Загрузка модели языка SpaCy**:
    Для работы с английским языком:
    ```bash
    python -m spacy download en_core_web_lg
    python -m spacy download en_core_web_sm
    ```

    Для работы с русским языком:
    ```bash
    python -m spacy download ru_core_news_lg
    ```

5. **Запуск проекта**:
    ```bash
    python main.py
    ```

## Взаимодействие с программой

После запуска программы будут выполнены следующие шаги:

1. **Чтение и предобработка текстов** — Программа прочитает все `.txt` файлы в директории `data/` и выполнит предобработку текста (удаление стоп-слов, лемматизация).
2. **Генерация эмбеддингов** — Для каждого предобработанного текста будут созданы эмбеддинги с использованием модели `sentence-transformers`.
3. **Определение оптимального числа кластеров** — Построение графиков для метода локтя и силуэтного коэффициента. После этого пользователю предлагается ввести оптимальное количество кластеров.
4. **Кластеризация** — Программа выполнит кластеризацию текстов с использованием алгоритма KMeans и сохранит модель.
5. **Классификация нового документа** — Пользователь может ввести новый текст для классификации, и программа отнесет его к ближайшему кластеру.

## Данные

Для работы проекта требуется наличие текстовых файлов в директории `data/`. Эти файлы будут использоваться для анализа, обработки и кластеризации.

## Требования

Проект требует Python 3.10 и выше. Зависимости перечислены в `requirements.txt`. Дополнительно требуется установка модели SpaCy для выбранного языка (английского или русского).
